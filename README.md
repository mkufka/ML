# Fruit Classification - MobileNetV2 Transfer Learning

Dieses Projekt verwendet **MobileNetV2 Transfer Learning** zur Klassifikation von 9 verschiedenen Obstsorten.

---

## ğŸš€ Schnellstart

### Voraussetzungen

1. **Python 3.11** (oder neuer) muss installiert sein --> getestet auf 3.11.9 und 3.13.7
2. **AbhÃ¤ngigkeiten installieren** (falls noch nicht vorhanden):
   ```bash
   pip install tensorflow numpy matplotlib scikit-learn pillow
   ```

   > **Hinweis:** Das Projekt enthÃ¤lt bereits ein vorkonfiguriertes `venv/`-Verzeichnis. Falls Sie dieses nutzen mÃ¶chten, aktivieren Sie es mit `.\venv\Scripts\activate` (Windows) oder `source venv/bin/activate` (Linux/Mac).

### Projekt verwenden

#### Option A: Nur Vorhersagen (schnell)
Wenn das Modell bereits trainiert ist (`model_output/best_fruit_classifier_cnn.keras` existiert):

1. Ã–ffnen Sie `Fruit_Prediction_Only.ipynb` in Jupyter Notebook oder VS Code
2. Legen Sie Ihre Obstbilder in den `Obst`-Ordner
3. FÃ¼hren Sie alle Zellen aus

#### Option B: Modell selbst trainieren
1. Stellen Sie sicher, dass Trainingsdaten im `Bilder/Training/` und `Bilder/Test/` Ordner vorhanden sind
2. Ã–ffnen Sie `Fruit_Classification_CNN_Complete.ipynb`
3. FÃ¼hren Sie alle Zellen der Reihe nach aus
4. Das Training dauert ca. 10-30 Minuten (je nach Hardware)

---

## âš ï¸ Wichtig: Worauf Sie achten mÃ¼ssen

### 1. Bildformat fÃ¼r optimale Ergebnisse
Das Modell wurde auf dem **Fruits-360 Dataset** trainiert. FÃ¼r beste Ergebnisse sollten Ihre Bilder folgende Eigenschaften haben:

| âœ… Optimal | âŒ Problematisch |
|-----------|------------------|
| WeiÃŸer/heller Hintergrund | Komplexe HintergrÃ¼nde |
| Einzelne, ganze Frucht | Aufgeschnittene FrÃ¼chte |
| Frucht zentriert | Mehrere FrÃ¼chte im Bild |
| Keine Wasserzeichen | Shutterstock/Stock-Photo Watermarks |
| Gute Beleuchtung | Schatten oder Ãœberbelichtung |

### 2. Trainingsdaten-Struktur
Die Trainingsbilder mÃ¼ssen in folgender Struktur vorliegen:
```
Bilder/
â”œâ”€â”€ Training/
â”‚   â”œâ”€â”€ Apple */       # Ordner die mit "Apple" beginnen
â”‚   â”œâ”€â”€ Banana */
â”‚   â”œâ”€â”€ Cherry */
â”‚   â””â”€â”€ ...
â””â”€â”€ Test/
    â”œâ”€â”€ Apple */
    â”œâ”€â”€ Banana */
    â””â”€â”€ ...
```

### 3. GPU-Nutzung (empfohlen)
- Mit GPU: Training in ~10 Minuten
- Ohne GPU (nur CPU): Training in ~30+ Minuten
- TensorFlow erkennt CUDA-fÃ¤hige GPUs automatisch

### 4. Speicherplatz
- Trainingsdaten: ~500 MB (gefiltert)
- Trainiertes Modell: ~6 MB
- TemporÃ¤re Daten: ~500 MB im `filtered_data/` Ordner

---

## ğŸ“Š Modell-Architektur

### **MobileNetV2 Transfer Learning**

Das Modell besteht aus zwei Teilen:

#### **1. Feature Extractor: MobileNetV2 (eingefroren)**
- Vortrainiert auf **ImageNet** (1.4 Millionen echte Fotos, 1000 Klassen)
- Erkennt bereits allgemeine visuelle Features (Kanten, Texturen, Formen, Farben)
- Layer sind **eingefroren** (werden nicht mittrainiert)
- Verwendet Global Average Pooling am Ende

#### **2. Custom Classifier (trainierbar)**
- **BatchNormalization** â†’ Stabilisierung
- **Dropout (0.3)** â†’ Overfitting-Schutz
- **Dense (256, ReLU)** â†’ Feature-Kombination
- **BatchNormalization** â†’ Stabilisierung
- **Dropout (0.3)** â†’ Overfitting-Schutz
- **Dense (9, Softmax)** â†’ Output fÃ¼r 9 Obstklassen

---

### **Modell-Statistiken:**
- **Basismodell:** MobileNetV2 (vortrainiert auf ImageNet)
- **Trainierbare Parameter:** nur der Classifier-Teil (~330K)
- **Nicht-trainierbare Parameter:** ~2.2M (eingefrorene MobileNetV2-Weights)
- **Architektur-Typ:** Transfer Learning
- **Preprocessing:** MobileNetV2 `preprocess_input` (skaliert Pixel auf [-1, 1])

**Vorteile gegenÃ¼ber Custom CNN:**
- âœ… Schnelleres Training (nur Classifier wird trainiert)
- âœ… Bessere Generalisierung durch vortrainierte Features
- âœ… Robuster gegen StÃ¶rungen (Watermarks, verschiedene HintergrÃ¼nde)
- âœ… Weniger Overfitting bei kleinen DatensÃ¤tzen

---

## ğŸ§  Wichtige Konzepte

### **1. Transfer Learning** ğŸ”„
**Was ist das?**
- Ein **vortrainiertes Modell** (MobileNetV2, trainiert auf ImageNet) wird als Basis verwendet
- Das Modell hat bereits gelernt, **allgemeine visuelle Features** zu erkennen
- Wir frieren diese Layer ein und trainieren nur einen neuen **Classifier** fÃ¼r unsere Obstklassen

**Vorteile:**
- Viel **weniger Trainingsdaten** nÃ¶tig
- **Schnelleres** Training
- **Bessere** Generalisierung
- **Robuster** gegen Variationen in den Bildern

---

### **2. MobileNetV2** ğŸ“±
**Was ist das?**
- Ein **effizientes** CNN, entwickelt von Google
- Vortrainiert auf **ImageNet** (1.4M Bilder, 1000 Klassen)
- Verwendet **Depthwise Separable Convolutions** fÃ¼r weniger Parameter
- Ideal fÃ¼r **mobile und eingebettete Anwendungen**

---

### **3. BatchNormalization** âš–ï¸
**Was macht es?**
- **Normalisiert** die Werte zwischen den Layern
- Macht das Training **stabiler und schneller**
- Verhindert, dass Werte zu groÃŸ oder zu klein werden

---

### **4. Dropout** ğŸ²
**Was macht es?**
- Schaltet **zufÃ¤llig** einige Neuronen wÃ¤hrend des Trainings aus
- Verhindert **Overfitting** (dass das Modell die Trainingsdaten auswendig lernt)
- In diesem Modell: 0.3 = 30% der Neuronen werden ausgeschaltet

---

### **5. Dense (Fully Connected Layer)** ğŸ”—
**Was macht er?**
- **Klassischer neuronaler Layer** - jedes Neuron ist mit allen vorherigen verbunden
- Kombiniert alle gelernten Features zu einer Entscheidung

---

### **6. Softmax (Aktivierungsfunktion im Output)** ğŸ“Š
**Was macht sie?**
- Wandelt die 9 Output-Werte in **Wahrscheinlichkeiten** um (0-100%)
- Alle Wahrscheinlichkeiten zusammen ergeben **100%**

**Beispiel:**
```
Rohwerte:           Nach Softmax:
Apple:    2.5  â†’    Apple:      85%
Banana:   0.3  â†’    Banana:     10%
Cherry:  -1.2  â†’    Cherry:      2%
...                 ...
                    Summe:     100%
```

---

## ğŸ”„ Datenfluss durch das Modell

```
Bild (100Ã—100Ã—3)
    â†“
MobileNetV2 preprocess_input (skaliert auf [-1, 1])
    â†“
MobileNetV2 Feature Extractor (eingefroren)
    â†“ (1280 Features via Global Average Pooling)
BatchNormalization
    â†“
Dropout (0.3)
    â†“
Dense(256, ReLU)
    â†“
BatchNormalization
    â†“
Dropout (0.3)
    â†“
Dense(9) + Softmax
    â†“
[Apple: 85%, Banana: 10%, Cherry: 2%, ...]
```

---

## ğŸ“ Komponenten Zusammenfassung

| Komponente | Funktion |
|-----------|----------|
| **MobileNetV2** | Vortrainierter Feature Extractor |
| **BatchNorm** | Stabilisierung |
| **Dropout** | Overfitting-Schutz |
| **Dense** | Entscheidungsfindung |
| **Softmax** | Wahrscheinlichkeiten |

---

## ğŸ Klassifizierte Obstsorten

Das Modell kann folgende 9 Obstsorten erkennen:

1. Apple (Apfel)
2. Banana (Banane)
3. Cherry (Kirsche)
4. Kiwi
5. Lemon (Zitrone)
6. Orange
7. Peach (Pfirsich)
8. Strawberry (Erdbeere)
9. Tomato (Tomate)

---

## ğŸ“ Projektstruktur

```
ML/
â”œâ”€â”€ Fruit_Classification_CNN_Complete.ipynb  # VollstÃ¤ndiges Training
â”œâ”€â”€ Fruit_Prediction_Only.ipynb              # Nur Vorhersagen (lÃ¤dt trainiertes Modell)
â”œâ”€â”€ model_output/                            # Gespeicherte Modelle
â”‚   â”œâ”€â”€ best_fruit_classifier_cnn.keras      # Bestes trainiertes Modell
â”‚   â””â”€â”€ label_mapping_cnn.json               # Label-Mapping (Index â†’ Klassenname)
â”œâ”€â”€ Bilder/                                  # Trainingsdaten
â”‚   â”œâ”€â”€ Training/                            # Trainingsbilder
â”‚   â””â”€â”€ Test/                                # Testbilder
â”œâ”€â”€ diagnose_model.py                        # Modell-Diagnose-Skript
â”œâ”€â”€ analyze_apple_image.py                   # Bild-Analyse-Skript
â””â”€â”€ README.md                                # Diese Datei
```

---

## ğŸš€ Verwendung

### Training (vollstÃ¤ndig):
Ã–ffnen Sie `Fruit_Classification_CNN_Complete.ipynb` und fÃ¼hren Sie alle Zellen aus.

### Nur Vorhersagen (schnell):
Ã–ffnen Sie `Fruit_Prediction_Only.ipynb` - lÃ¤dt das bereits trainierte Modell in Sekunden!

---

## âš ï¸ Wichtige Hinweise

Das Modell funktioniert am besten mit Bildern, die:
- **WeiÃŸen Hintergrund** haben
- **100Ã—100 Pixel** groÃŸ sind (oder automatisch skaliert werden)
- **Zentriertes Obst** zeigen
- **Gute Beleuchtung** haben

Bilder mit anderem Hintergrund oder Stil kÃ¶nnen zu falschen Vorhersagen fÃ¼hren!

