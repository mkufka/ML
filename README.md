# Fruit Classification CNN - Dokumentation

Dieses Projekt verwendet ein Convolutional Neural Network (CNN) zur Klassifikation von 9 verschiedenen Obstsorten.

---

## ğŸš€ Schnellstart

### Voraussetzungen

1. **Python 3.11** (oder neuer) muss installiert sein --> getestet auf 3.11.9 und 3.13.7
2. **Virtual Environment** erstellen und aktivieren:
   ```bash
   # Windows
   python -m venv venv
   .\venv\Scripts\activate

   # Linux/Mac
   python -m venv venv
   source venv/bin/activate
   ```

3. **AbhÃ¤ngigkeiten installieren:**
   ```bash
   pip install tensorflow numpy matplotlib scikit-learn pillow
   ```

### Projekt verwenden

#### Option A: Nur Vorhersagen (schnell)
Wenn das Modell bereits trainiert ist (`model_output/best_fruit_classifier_cnn.keras` existiert):

1. Ã–ffnen Sie `Fruit_Prediction_Only.ipynb` in Jupyter Notebook oder VS Code
2. Legen Sie Ihre Obstbilder in den `Obst`-Ordner
3. FÃ¼hren Sie alle Zellen aus

#### Option B: Modell selbst trainieren
1. Stellen Sie sicher, dass Trainingsdaten im `Bilder/Training/` und `Bilder/Test/` Ordner vorhanden sind
2. Ã–ffnen Sie `Fruit_Classification_CNN_Complete.ipynb`
3. FÃ¼hren Sie alle Zellen der Reihe nach aus
4. Das Training dauert ca. 10-30 Minuten (je nach Hardware)

---

## âš ï¸ Wichtig: Worauf Sie achten mÃ¼ssen

### 1. Bildformat fÃ¼r optimale Ergebnisse
Das Modell wurde auf dem **Fruits-360 Dataset** trainiert. FÃ¼r beste Ergebnisse sollten Ihre Bilder folgende Eigenschaften haben:

| âœ… Optimal | âŒ Problematisch |
|-----------|------------------|
| WeiÃŸer/heller Hintergrund | Komplexe HintergrÃ¼nde |
| Einzelne, ganze Frucht | Aufgeschnittene FrÃ¼chte |
| Frucht zentriert | Mehrere FrÃ¼chte im Bild |
| Keine Wasserzeichen | Shutterstock/Stock-Photo Watermarks |
| Gute Beleuchtung | Schatten oder Ãœberbelichtung |

### 2. Trainingsdaten-Struktur
Die Trainingsbilder mÃ¼ssen in folgender Struktur vorliegen:
```
Bilder/
â”œâ”€â”€ Training/
â”‚   â”œâ”€â”€ Apple */       # Ordner die mit "Apple" beginnen
â”‚   â”œâ”€â”€ Banana */
â”‚   â”œâ”€â”€ Cherry */
â”‚   â””â”€â”€ ...
â””â”€â”€ Test/
    â”œâ”€â”€ Apple */
    â”œâ”€â”€ Banana */
    â””â”€â”€ ...
```

### 3. GPU-Nutzung (empfohlen)
- Mit GPU: Training in ~10 Minuten
- Ohne GPU (nur CPU): Training in ~30+ Minuten
- TensorFlow erkennt CUDA-fÃ¤hige GPUs automatisch

### 4. Speicherplatz
- Trainingsdaten: ~500 MB (gefiltert)
- Trainiertes Modell: ~6 MB
- TemporÃ¤re Daten: ~500 MB im `filtered_data/` Ordner

---

## ğŸ“Š Modell-Architektur

### **Gesamt: 27 Layer**

Aufgeteilt in:

#### **1. Convolutional Blocks (4 BlÃ¶cke):**
- **Block 1:** 2Ã— Conv2D (32 Filter) + 2Ã— BatchNorm + MaxPooling + Dropout = **6 Layer**
- **Block 2:** 2Ã— Conv2D (64 Filter) + 2Ã— BatchNorm + MaxPooling + Dropout = **6 Layer**
- **Block 3:** 2Ã— Conv2D (128 Filter) + 2Ã— BatchNorm + MaxPooling + Dropout = **6 Layer**
- **Block 4:** 2Ã— Conv2D (256 Filter) + 2Ã— BatchNorm + MaxPooling + Dropout = **6 Layer**

**Convolutional Teil: 24 Layer**

#### **2. Fully Connected Teil:**
- **GlobalAveragePooling2D** = **1 Layer**
- **Dense (512) + BatchNorm + Dropout** = **3 Layer**
- **Dense (256) + BatchNorm + Dropout** = **3 Layer**
- **Output Dense (9 Klassen) mit Softmax** = **1 Layer**

**Dense Teil: 8 Layer**

---

### **Modell-Statistiken:**
- **Insgesamt: 27 Layer**
- **Trainierbare Parameter: 1.440.937** (ca. 1,4 Millionen)
- **Architektur-Typ:** Custom CNN (Convolutional Neural Network)
- **4 Convolutional Blocks** mit steigender Filterzahl (32 â†’ 64 â†’ 128 â†’ 256)
- **2 Dense Hidden Layers** (512 â†’ 256)
- **Output Layer** mit 9 Neuronen (fÃ¼r 9 Obstklassen)

Das ist ein **mittelgroÃŸes CNN** - nicht zu klein (wÃ¼rde underfitting verursachen), nicht zu groÃŸ (wÃ¼rde overfitting verursachen). Perfekt fÃ¼r 9 Obstklassen! ğŸğŸŒğŸŠ

---

## ğŸ§  Layer-Typen ErklÃ¤rt

### **1. Conv2D (Convolutional Layer)** ğŸ”
**Was macht er?**
- Erkennt **Muster und Features** im Bild (z.B. Kanten, Farben, Texturen)
- Verwendet kleine **Filter** (3Ã—3 Pixel), die Ã¼ber das Bild "gleiten"
- FrÃ¼he Layer erkennen einfache Muster (Kanten), tiefe Layer erkennen komplexe Muster (Formen, Objekte)

**In diesem Modell:**
- Block 1: 32 Filter (erkennt 32 verschiedene einfache Muster)
- Block 2: 64 Filter (erkennt 64 komplexere Muster)
- Block 3: 128 Filter
- Block 4: 256 Filter (erkennt sehr komplexe Features wie "Apfelform" oder "BananenkrÃ¼mmung")

**Beispiel:** Ein Filter kÃ¶nnte spezialisiert sein auf "rote runde Formen" â†’ Apfel!

---

### **2. BatchNormalization** âš–ï¸
**Was macht er?**
- **Normalisiert** die Werte zwischen den Layern
- Macht das Training **stabiler und schneller**
- Verhindert, dass Werte zu groÃŸ oder zu klein werden

**Analogie:** Wie ein Thermostat, der die Temperatur konstant hÃ¤lt, damit nichts Ã¼berhitzt oder einfriert.

---

### **3. MaxPooling2D** ğŸ“‰
**Was macht er?**
- **Verkleinert** das Bild (z.B. von 100Ã—100 auf 50Ã—50)
- Nimmt nur die **wichtigsten Informationen** (Maximum aus jedem 2Ã—2 Bereich)
- Reduziert Rechenaufwand und macht das Modell robuster

**Beispiel:** 
```
Vorher (4Ã—4):     Nachher (2Ã—2):
[1 3 2 4]         [3 8]
[2 1 5 8]    â†’    [9 7]
[6 9 3 2]
[4 7 1 5]
```
Nimmt jeweils das Maximum aus jedem 2Ã—2 Block.

---

### **4. Dropout** ğŸ²
**Was macht er?**
- Schaltet **zufÃ¤llig** einige Neuronen wÃ¤hrend des Trainings aus (z.B. 25% oder 50%)
- Verhindert **Overfitting** (dass das Modell die Trainingsdaten auswendig lernt)
- Zwingt das Modell, robuster zu werden

**Analogie:** Wie ein FuÃŸballteam, das auch mit 10 statt 11 Spielern trainiert, damit es flexibler wird.

**In diesem Modell:**
- 0.25 = 25% der Neuronen werden ausgeschaltet (in Conv-BlÃ¶cken)
- 0.5 = 50% der Neuronen werden ausgeschaltet (in Dense-Layern)

---

### **5. GlobalAveragePooling2D** ğŸŒ
**Was macht er?**
- Nimmt den **Durchschnitt** aller Werte in jedem Feature-Map
- Wandelt z.B. 256 Feature-Maps (6Ã—6 Pixel) in 256 einzelne Zahlen um
- Reduziert massiv die Parameter-Anzahl

**Beispiel:**
```
Feature-Map (6Ã—6):        Ergebnis:
[1 2 3 4 5 6]
[2 3 4 5 6 7]       â†’     Durchschnitt = 4.5
[3 4 5 6 7 8]
...
```

---

### **6. Dense (Fully Connected Layer)** ğŸ”—
**Was macht er?**
- **Klassischer neuronaler Layer** - jedes Neuron ist mit allen vorherigen verbunden
- Kombiniert alle gelernten Features zu einer Entscheidung
- Die letzten Dense-Layer "denken" Ã¼ber die Features nach

**In diesem Modell:**
- Dense(512): 512 Neuronen kombinieren Features
- Dense(256): 256 Neuronen verfeinern die Entscheidung
- Dense(9): **Output-Layer** - 9 Neuronen (eine pro Obstsorte)

---

### **7. Softmax (Aktivierungsfunktion im Output)** ğŸ“Š
**Was macht sie?**
- Wandelt die 9 Output-Werte in **Wahrscheinlichkeiten** um (0-100%)
- Alle Wahrscheinlichkeiten zusammen ergeben **100%**

**Beispiel:**
```
Rohwerte:           Nach Softmax:
Apple:    2.5  â†’    Apple:      85%
Banana:   0.3  â†’    Banana:     10%
Cherry:  -1.2  â†’    Cherry:      2%
...                 ...
                    Summe:     100%
```

---

## ğŸ”„ Datenfluss durch das Modell

```
Bild (100Ã—100Ã—3)
    â†“
[Conv2D â†’ BatchNorm â†’ Conv2D â†’ BatchNorm â†’ MaxPool â†’ Dropout]  â† Block 1
    â†“ (50Ã—50Ã—32)
[Conv2D â†’ BatchNorm â†’ Conv2D â†’ BatchNorm â†’ MaxPool â†’ Dropout]  â† Block 2
    â†“ (25Ã—25Ã—64)
[Conv2D â†’ BatchNorm â†’ Conv2D â†’ BatchNorm â†’ MaxPool â†’ Dropout]  â† Block 3
    â†“ (12Ã—12Ã—128)
[Conv2D â†’ BatchNorm â†’ Conv2D â†’ BatchNorm â†’ MaxPool â†’ Dropout]  â† Block 4
    â†“ (6Ã—6Ã—256)
GlobalAveragePooling2D
    â†“ (256 Zahlen)
Dense(512) â†’ BatchNorm â†’ Dropout
    â†“ (512 Zahlen)
Dense(256) â†’ BatchNorm â†’ Dropout
    â†“ (256 Zahlen)
Dense(9) + Softmax
    â†“
[Apple: 85%, Banana: 10%, Cherry: 2%, ...]
```

---

## ğŸ“ Layer-Typen Zusammenfassung

| Layer-Typ | Funktion |
|-----------|----------|
| **Conv2D** | Mustererkennung |
| **BatchNorm** | Stabilisierung |
| **MaxPooling** | Verkleinerung |
| **Dropout** | Overfitting-Schutz |
| **GlobalAveragePooling** | Komprimierung |
| **Dense** | Entscheidungsfindung |
| **Softmax** | Wahrscheinlichkeiten |

---

## ğŸ Klassifizierte Obstsorten

Das Modell kann folgende 9 Obstsorten erkennen:

1. Apple (Apfel)
2. Banana (Banane)
3. Cherry (Kirsche)
4. Kiwi
5. Lemon (Zitrone)
6. Orange
7. Peach (Pfirsich)
8. Strawberry (Erdbeere)
9. Tomato (Tomate)

---

## ğŸ“ Projektstruktur

```
ML/
â”œâ”€â”€ Fruit_Classification_CNN_Complete.ipynb  # VollstÃ¤ndiges Training
â”œâ”€â”€ Fruit_Prediction_Only.ipynb              # Nur Vorhersagen (lÃ¤dt trainiertes Modell)
â”œâ”€â”€ model_output/                            # Gespeicherte Modelle
â”‚   â”œâ”€â”€ best_fruit_classifier_cnn.keras      # Bestes trainiertes Modell
â”‚   â””â”€â”€ label_mapping_cnn.json               # Label-Mapping (Index â†’ Klassenname)
â”œâ”€â”€ Bilder/                                  # Trainingsdaten
â”‚   â”œâ”€â”€ Training/                            # Trainingsbilder
â”‚   â””â”€â”€ Test/                                # Testbilder
â”œâ”€â”€ diagnose_model.py                        # Modell-Diagnose-Skript
â”œâ”€â”€ analyze_apple_image.py                   # Bild-Analyse-Skript
â””â”€â”€ README.md                                # Diese Datei
```

---

## ğŸš€ Verwendung

### Training (vollstÃ¤ndig):
Ã–ffnen Sie `Fruit_Classification_CNN_Complete.ipynb` und fÃ¼hren Sie alle Zellen aus.

### Nur Vorhersagen (schnell):
Ã–ffnen Sie `Fruit_Prediction_Only.ipynb` - lÃ¤dt das bereits trainierte Modell in Sekunden!

---

## âš ï¸ Wichtige Hinweise

Das Modell funktioniert am besten mit Bildern, die:
- **WeiÃŸen Hintergrund** haben
- **100Ã—100 Pixel** groÃŸ sind (oder automatisch skaliert werden)
- **Zentriertes Obst** zeigen
- **Gute Beleuchtung** haben

Bilder mit anderem Hintergrund oder Stil kÃ¶nnen zu falschen Vorhersagen fÃ¼hren!

